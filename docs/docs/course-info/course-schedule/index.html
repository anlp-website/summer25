<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Schedule
  #


  Important
All deadline and due dates in this course will be at AoE time zone. For all dates used in this course, their times are 23:59 Anywhere on Earth (11:59 pm AoE). For example, a due date of &ldquo;January 8&rdquo; is the same as &ldquo;January 8, 23:59pm AoE&rdquo;. Convert the times to your local times using a Time Zone Converter.




  Scroll horizontally to see the full schedule table on mobile devices


 

  
    
      
        Week
        Dates
        Topics
        Homework
        Quizzes
        Readings
      
    
    
      
      
        1
        5/12 - 5/16
        
          
            
            Course introduction
            
            Text data preprocessing: Normalization, lemmatization, stemming, stop words removal&hellip;
            
            Text Representations:
            
            One hot encoding
            
            BoW (frequency counting)
            
            TF-IDF
            
          
        
        
          
            
            HW1 out 5/16
            
          
        
        Quiz 0 | Knowledge-based | out 5/12 - due 5/16
        
          
            
            Chapter 1 Introduction to Natural Language Processing by Jacob Eisenstein
            
            Chapter 2.1 Introduction to Natural Language Processing by Jacob Eisenstein
            
          
        
      
      
      
        2
        5/19 - 5/23
        
          
            
            Classification Introduction
            
            Naive Bayes
            
            Classification Model Evaluation: accuracy, precision, recall, confusion matrix
            
          
        
        
          
            
          
        
        Quiz 1 | week 1| out 5/16 - due 5/23
        
          
            
            Chapter 2.2 Introduction to Natural Language Processing by Jacob Eisenstein
            
          
        
      
      
      
        3
        5/26 - 5/30
        
          
            
            Memorial Day Institute Holiday
            
            Logistic Regression
            
            SVM
            
            Perceptron
            
          
        
        
          
            
            HW1 due 5/30
            
            HW2 out 5/30
            
          
        
        Quiz 2 | week 2| out 5/23 - due 5/30
        
          
            
            Chapters 2.3, 2.4, 2.5 Introduction to Natural Language Processing by Jacob Eisenstein.
            
          
        
      
      
      
        4
        6/02 - 6/06
        
          
            
            SVD (Dimensionality Reduction) &#43; Co-occurrence embeddings
            
            Glove
            
          
        
        
          
            
          
        
        Quiz 3 | week 3| out 5/30 - due 6/06
        
          
            
            GloVe: Global Vectors for Word Representation
            
          
        
      
      
      
        5
        6/09 - 6/13
        
          
            
            Neural Network (fully connected)
            
            Word2vec: CBoW, Skip-Gram
            
            Toolbox on Classification Algorithms
            
            Toolbox on Word2Vec
            
          
        
        
          
            
            HW2 due 6/13
            
            HW3 out 6/13
            
          
        
        Quiz 4 | week 4| out 6/06 - due 6/13
        
          
            
            NN Playground
            
            Interactive NN initialization;
            
            The role of a hidden layer;
            
            Back propagation numerical example;
            
            More detailed introduction;
            
            Efficient Estimation of Word Representations in Vector Space
            
          
        
      
      
      
        6
        6/16 - 6/20
        
          
            
            Juneteenth Institute Holiday
            
            CNN
            
            RNN
            
            Toolbox on CNN For Text Classification
            
          
        
        
          
            
          
        
        Quiz 5 | week 5| out 6/13 - due 6/20
        
          
            
            CNN Live Demo;
            
            A guide to an efficient way to build CNN and optimize its hyper-parameters;
            
            Back Propagation in CNN;
            
            Transfer learning in CNN;
            
          
        
      
      
      
        7
        6/23 - 6/27
        
          
            
            LSTM and GRU
            
            LSTM &#43; Attention (Focus on Attention mechanism)
            
            Independe Day Institute Holiday
            
          
        
        
          
            
          
        
        Quiz 6 | week 6| out 6/23 - due 6/27
        
          
            
          
        
      
      
      
        8
        6/30 - 7/04
        
          
            
            Transformer models
            
            Examples: BERT(Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer)
            
          
        
        
          
            
            HW3 due 7/04
            
            H4 out 7/04
            
          
        
        Quiz 7 | week 7| out 6/27 - due 7/04
        
          
            
            Attention Is All You Need;
            
            BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;
            
          
        
      
      
      
        9
        7/07 - 7/11
        
          
            
            Sequence Labelling: POS Tagging
            
            Sequen1e Labelling: NER
            
          
        
        
          
            
          
        
        Quiz 8 | week 8| out 7/04 - due 7/11
        
          
            
          
        
      
      
      
        10
        7/14 - 7/18
        
          
            
            Unsupervised Models
            
            Topic Modeling (Latent Semantic Indexing, LDA (Latent Dirichlet Allocation)
            
            Toolbox on Exploring LLMs
            
          
        
        
          
            
          
        
        Quiz 9 | week 9| out 7/11 - due 7/18
        
          
            
          
        
      
      
      
        11
        7/21 - 7/22
        
          
            
            Introduction to Generative AI
            
            Prompt Engineering Techniques
            
            Retrieval Augmented Generation (RAG)
            
          
        
        
          
            
            HW4 due 7/25
            
          
        
        Quiz 10 | week 10 | out 7/18 - due 7/25
        
          
            
          
        
      
      
    
  


">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="/docs/course-info/course-schedule/">
  <meta property="og:site_name" content="Class Homepage">
  <meta property="og:title" content="Course Schedule">
  <meta property="og:description" content="Schedule#Important
All deadline and due dates in this course will be at AoE time zone. For all dates used in this course, their times are 23:59 Anywhere on Earth (11:59 pm AoE). For example, a due date of “January 8” is the same as “January 8, 23:59pm AoE”. Convert the times to your local times using a Time Zone Converter.
Scroll horizontally to see the full schedule table on mobile devicesWeekDatesTopicsHomeworkQuizzesReadings15/12 - 5/16Course introductionText data preprocessing: Normalization, lemmatization, stemming, stop words removal…Text Representations:One hot encodingBoW (frequency counting)TF-IDFHW1 out 5/16Quiz 0 | Knowledge-based | out 5/12 - due 5/16Chapter 1 Introduction to Natural Language Processing by Jacob EisensteinChapter 2.1 Introduction to Natural Language Processing by Jacob Eisenstein25/19 - 5/23Classification IntroductionNaive BayesClassification Model Evaluation: accuracy, precision, recall, confusion matrixQuiz 1 | week 1| out 5/16 - due 5/23Chapter 2.2 Introduction to Natural Language Processing by Jacob Eisenstein35/26 - 5/30Memorial Day Institute HolidayLogistic RegressionSVMPerceptronHW1 due 5/30HW2 out 5/30Quiz 2 | week 2| out 5/23 - due 5/30Chapters 2.3, 2.4, 2.5 Introduction to Natural Language Processing by Jacob Eisenstein.46/02 - 6/06SVD (Dimensionality Reduction) &#43; Co-occurrence embeddingsGloveQuiz 3 | week 3| out 5/30 - due 6/06GloVe: Global Vectors for Word Representation56/09 - 6/13Neural Network (fully connected)Word2vec: CBoW, Skip-GramToolbox on Classification AlgorithmsToolbox on Word2VecHW2 due 6/13HW3 out 6/13Quiz 4 | week 4| out 6/06 - due 6/13NN PlaygroundInteractive NN initialization;The role of a hidden layer;Back propagation numerical example;More detailed introduction;Efficient Estimation of Word Representations in Vector Space66/16 - 6/20Juneteenth Institute HolidayCNNRNNToolbox on CNN For Text ClassificationQuiz 5 | week 5| out 6/13 - due 6/20CNN Live Demo;A guide to an efficient way to build CNN and optimize its hyper-parameters;Back Propagation in CNN;Transfer learning in CNN;76/23 - 6/27LSTM and GRULSTM &#43; Attention (Focus on Attention mechanism)Independe Day Institute HolidayQuiz 6 | week 6| out 6/23 - due 6/2786/30 - 7/04Transformer modelsExamples: BERT(Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer)HW3 due 7/04H4 out 7/04Quiz 7 | week 7| out 6/27 - due 7/04Attention Is All You Need;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;97/07 - 7/11Sequence Labelling: POS TaggingSequen1e Labelling: NERQuiz 8 | week 8| out 7/04 - due 7/11107/14 - 7/18Unsupervised ModelsTopic Modeling (Latent Semantic Indexing, LDA (Latent Dirichlet Allocation)Toolbox on Exploring LLMsQuiz 9 | week 9| out 7/11 - due 7/18117/21 - 7/22Introduction to Generative AIPrompt Engineering TechniquesRetrieval Augmented Generation (RAG)HW4 due 7/25Quiz 10 | week 10 | out 7/18 - due 7/25">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
<title>Course Schedule | Class Homepage</title>
<link rel="manifest" href="../../../manifest.json">
<link rel="icon" href="../../../favicon.png" type="image/x-icon">
<link rel="stylesheet" href="../../../book.min.7b6241443fe1f51d9fd9746bc5c4ae10ddc004bf189bcd20d3be1689dfb8c46d.css" ><!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="../../../"><img src="../../../favicon.ico" alt="Logo" /><span>Class Homepage</span>
  </a>
</h2>













  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Course Info</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="../../../docs/course-info/course-overview/" class="">Course Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="../../../docs/course-info/instructors-and-tas/" class="">Instructor and TAs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="../../../docs/course-info/course-schedule/" class="active">Course Schedule</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Guidelines</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="../../../docs/guidelines/general/" class="">General</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="../../../docs/guidelines/office-hours/" class="">Office Hours</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="../../../docs/guidelines/diversity-and-inclusion/" class="">Diversity &amp; Inclusion</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Grading</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="../../../docs/grading/categories/" class="">Categories</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Resources</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="../../../docs/resources/collection/" class="">Collection</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="../../../svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Course Schedule</strong>

  <label for="toc-control">
    
  </label>
</div>


  
 
      </header>

      
      
  <article class="markdown"><h1 id="schedule">
  Schedule
  <a class="anchor" href="#schedule">#</a>
</h1>
<blockquote class="book-hint info">
  <p><strong>Important</strong><br>
All deadline and due dates in this course will be at AoE time zone. For all dates used in this course, their times are 23:59 Anywhere on Earth (11:59 pm AoE). For example, a due date of &ldquo;January 8&rdquo; is the same as &ldquo;January 8, 23:59pm AoE&rdquo;. Convert the times to your local times using a <a href="https://www.timeanddate.com/worldclock/converter.html?iso=20180109T115900&amp;p1=tz_aoe&amp;p2=tz_et&amp;p3=tz_pt&amp;p4=1440">Time Zone Converter</a>.</p>
<!-- All deadline and due dates in this course will be at 23:59 ET. -->
</blockquote>

<blockquote class="book-hint warning">
  Scroll horizontally to see the full schedule table on mobile devices
</blockquote>

 
<div class="table-responsive">
  <table>
    <thead>
      <tr>
        <th width="3%">Week</th>
        <th width="12%">Dates</th>
        <th width="35%">Topics</th>
        <th width="15%">Homework</th>
        <th width="15%">Quizzes</th>
        <th width="30%">Readings</th>
      </tr>
    </thead>
    <tbody>
      
      <tr>
        <td>1</td>
        <td>5/12 - 5/16</td>
        <td>
          <ul>
            
            <li>Course introduction</li>
            
            <li>Text data preprocessing: Normalization, lemmatization, stemming, stop words removal&hellip;</li>
            
            <li>Text Representations:</li>
            
            <li>One hot encoding</li>
            
            <li>BoW (frequency counting)</li>
            
            <li>TF-IDF</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
            <li>HW1 out 5/16</li>
            
          </ul>
        </td>
        <td>Quiz 0 | Knowledge-based | out 5/12 - due 5/16</td>
        <td>
          <ul>
            
            <li>Chapter 1 Introduction to Natural Language Processing by Jacob Eisenstein</li>
            
            <li>Chapter 2.1 Introduction to Natural Language Processing by Jacob Eisenstein</li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>2</td>
        <td>5/19 - 5/23</td>
        <td>
          <ul>
            
            <li>Classification Introduction</li>
            
            <li>Naive Bayes</li>
            
            <li>Classification Model Evaluation: accuracy, precision, recall, confusion matrix</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 1 | week 1| out 5/16 - due 5/23</td>
        <td>
          <ul>
            
            <li>Chapter 2.2 Introduction to Natural Language Processing by Jacob Eisenstein</li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>3</td>
        <td>5/26 - 5/30</td>
        <td>
          <ul>
            
            <li>Memorial Day Institute Holiday</li>
            
            <li>Logistic Regression</li>
            
            <li>SVM</li>
            
            <li>Perceptron</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
            <li><strong>HW1 due 5/30</strong></li>
            
            <li>HW2 out 5/30</li>
            
          </ul>
        </td>
        <td>Quiz 2 | week 2| out 5/23 - due 5/30</td>
        <td>
          <ul>
            
            <li>Chapters 2.3, 2.4, 2.5 Introduction to Natural Language Processing by Jacob Eisenstein.</li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>4</td>
        <td>6/02 - 6/06</td>
        <td>
          <ul>
            
            <li>SVD (Dimensionality Reduction) + Co-occurrence embeddings</li>
            
            <li>Glove</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 3 | week 3| out 5/30 - due 6/06</td>
        <td>
          <ul>
            
            <li><a href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation</a></li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>5</td>
        <td>6/09 - 6/13</td>
        <td>
          <ul>
            
            <li>Neural Network (fully connected)</li>
            
            <li>Word2vec: CBoW, Skip-Gram</li>
            
            <li>Toolbox on Classification Algorithms</li>
            
            <li>Toolbox on Word2Vec</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
            <li><strong>HW2 due 6/13</strong></li>
            
            <li>HW3 out 6/13</li>
            
          </ul>
        </td>
        <td>Quiz 4 | week 4| out 6/06 - due 6/13</td>
        <td>
          <ul>
            
            <li><a href="https://playground.tensorflow.org/">NN Playground</a></li>
            
            <li><a href="https://www.deeplearning.ai/ai-notes/initialization/">Interactive NN initialization</a>;</li>
            
            <li><a href="https://www.quora.com/What-is-the-role-of-a-hidden-layer">The role of a hidden layer</a>;</li>
            
            <li><a href="https://hmkcode.github.io/ai/backpropagation-step-by-step/">Back propagation numerical example</a>;</li>
            
            <li><a href="../../../other/nn-intro.pdf">More detailed introduction</a>;</li>
            
            <li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwid2L-eu4WAAxUPAjQIHds5CocQFnoECA8QAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1301.3781&amp;usg=AOvVaw2oae2AEKwhhz_ZlnfwIaFJ&amp;opi=89978449">Efficient Estimation of Word Representations in Vector Space</a></li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>6</td>
        <td>6/16 - 6/20</td>
        <td>
          <ul>
            
            <li>Juneteenth Institute Holiday</li>
            
            <li>CNN</li>
            
            <li>RNN</li>
            
            <li>Toolbox on CNN For Text Classification</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 5 | week 5| out 6/13 - due 6/20</td>
        <td>
          <ul>
            
            <li><a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html">CNN Live Demo</a>;</li>
            
            <li><a href="https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7">A guide to an efficient way to build CNN and optimize its hyper-parameters</a>;</li>
            
            <li><a href="https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/">Back Propagation in CNN</a>;</li>
            
            <li><a href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">Transfer learning in CNN</a>;</li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>7</td>
        <td>6/23 - 6/27</td>
        <td>
          <ul>
            
            <li>LSTM and GRU</li>
            
            <li>LSTM + Attention (Focus on Attention mechanism)</li>
            
            <li>Independe Day Institute Holiday</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 6 | week 6| out 6/23 - due 6/27</td>
        <td>
          <ul>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>8</td>
        <td>6/30 - 7/04</td>
        <td>
          <ul>
            
            <li>Transformer models</li>
            
            <li>Examples: BERT(Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer)</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
            <li><strong>HW3 due 7/04</strong></li>
            
            <li>H4 out 7/04</li>
            
          </ul>
        </td>
        <td>Quiz 7 | week 7| out 6/27 - due 7/04</td>
        <td>
          <ul>
            
            <li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwiPtd7Y9IWAAxU2JkQIHW1EDKIQFnoECA0QAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&amp;usg=AOvVaw2ceXGQohV5Kx51VSkfkG08&amp;opi=89978449">Attention Is All You Need</a>;</li>
            
            <li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwj3vITv9IWAAxUkOkQIHYjkApEQFnoECA0QAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1810.04805&amp;usg=AOvVaw14sm9MmA6c9pcfLHgrP9Pk&amp;opi=89978449">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>;</li>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>9</td>
        <td>7/07 - 7/11</td>
        <td>
          <ul>
            
            <li>Sequence Labelling: POS Tagging</li>
            
            <li>Sequen1e Labelling: NER</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 8 | week 8| out 7/04 - due 7/11</td>
        <td>
          <ul>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>10</td>
        <td>7/14 - 7/18</td>
        <td>
          <ul>
            
            <li>Unsupervised Models</li>
            
            <li>Topic Modeling (Latent Semantic Indexing, LDA (Latent Dirichlet Allocation)</li>
            
            <li>Toolbox on Exploring LLMs</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
          </ul>
        </td>
        <td>Quiz 9 | week 9| out 7/11 - due 7/18</td>
        <td>
          <ul>
            
          </ul>
        </td>
      </tr>
      
      <tr>
        <td>11</td>
        <td>7/21 - 7/22</td>
        <td>
          <ul>
            
            <li>Introduction to Generative AI</li>
            
            <li>Prompt Engineering Techniques</li>
            
            <li>Retrieval Augmented Generation (RAG)</li>
            
          </ul>
        </td>
        <td>
          <ul>
            
            <li><strong>HW4 due 7/25</strong></li>
            
          </ul>
        </td>
        <td>Quiz 10 | week 10 | out 7/18 - due 7/25</td>
        <td>
          <ul>
            
          </ul>
        </td>
      </tr>
      
    </tbody>
  </table>
</div>

<style>
  .table-responsive {
    font-size: 13px;
  }

  .table-responsive td {
    padding: 0.5rem !important;
  }

  .table-responsive ul,
  .table-responsive ol {
    display: block;
    list-style-type: disc;
    padding-inline-start: 1rem;
  }
</style>

</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  </main>

  
</body>
</html>












